{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mModelfile\u001b[0m*            \u001b[01;34mdemo\u001b[0m/                     \u001b[01;32mnaive_RAG.ipynb\u001b[0m*\n",
      "\u001b[01;34mPhoGPT-4B-Chat-gguf\u001b[0m/  \u001b[01;32mdemo.py\u001b[0m*                  \u001b[01;34mnltk_data\u001b[0m/\n",
      "\u001b[01;32mRAG_components.py\u001b[0m*    \u001b[01;32mdemo_RAG.ipynb\u001b[0m*           \u001b[01;32mqa_data.csv\u001b[0m*\n",
      "\u001b[01;32mRAG_test.ipynb\u001b[0m*       \u001b[01;32mdemo_using_models.ipynb\u001b[0m*  \u001b[01;32mqa_data.json\u001b[0m*\n",
      "\u001b[01;32mRAGapp.ipynb\u001b[0m*         \u001b[01;32mdjango-ui.ipynb\u001b[0m*          \u001b[01;34mresources\u001b[0m/\n",
      "\u001b[01;32m__init__.py\u001b[0m*          \u001b[01;32minstall.txt\u001b[0m*              \u001b[01;34mtest-dir\u001b[0m/\n",
      "\u001b[01;34m__pycache__\u001b[0m/          \u001b[01;34mlegal-documents\u001b[0m/          \u001b[01;34mvinallama-legal-chat\u001b[0m/\n",
      "\u001b[01;32madvanced_RAG.ipynb\u001b[0m*   \u001b[01;34mlog\u001b[0m/                      \u001b[01;34mvistral-7b-legal-chat-final\u001b[0m/\n",
      "\u001b[01;34mbge-m3\u001b[0m/               \u001b[01;32mmain.ipynb\u001b[0m*               \u001b[01;34mvistral-legal-chat\u001b[0m/\n",
      "\u001b[01;34mbge-small-en-v1.5\u001b[0m/    \u001b[01;34mmodelfiles\u001b[0m/               \u001b[01;34mweights\u001b[0m/\n",
      "\u001b[01;34mchat_engine\u001b[0m/          \u001b[01;34mmy_venv\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"chat_engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
    "from llama_index.core.storage.storage_context import StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core.schema import QueryBundle\n",
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.settings import Settings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from prompts import gen_qa_prompt, gen_rag_answer\n",
    "from RAG import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG import format_chatbot_output\n",
    "from RAG import RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_clean_column(file_path):\n",
    "    \"\"\"\n",
    "    Reads the first column of a CSV file, cleans up line breaks, \n",
    "    and returns a list of strings from the rows, skipping the header.\n",
    "    \n",
    "    :param file_path: Path to the CSV file\n",
    "    :return: List of cleaned strings from the first column\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    # Open the CSV file\n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        \n",
    "        # Skip the header\n",
    "        next(reader)\n",
    "        \n",
    "        # Iterate over the rows in the CSV\n",
    "        for row in reader:\n",
    "            if row:  # Make sure the row is not empty\n",
    "                # Join lines in the cell and clean up extra spaces/newlines\n",
    "                cleaned_text = ' '.join(row[0].split())\n",
    "                result.append(cleaned_text)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "file_path = 'answers-comparison-vistral.csv'\n",
    "questions = extract_and_clean_column(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_questions = [q for q in questions if q.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,question in enumerate(cleaned_questions):\n",
    "    index = index + 1\n",
    "    print('index', index)\n",
    "    print('question', question)\n",
    "    print(\"===============================================================\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://hunter/Vietnamese-law-RAG-semantic-chuning already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "rag = RAG(\n",
    "        model_name=\"vistral-legal-chat\"    # vistral, phogpt, vinallama\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for CSV\n",
    "csv_data = [[\"Question\", \"Answer\"]]  # Header row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Đối với hợp đồng vay không kỳ hạn và không có lãi thì bên cho vay có quyền đòi lại tài sản và bên vay cũng có quyền trả nợ vào bất cứ lúc nào có đúng không?'\n",
    "answer = rag.base_answer(question)\n",
    "final_answer = format_chatbot_output(answer)\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in cleaned_questions:\n",
    "    answer = rag.base_answer(question)\n",
    "    final_answer = format_chatbot_output(answer)\n",
    "    csv_data.append([question, final_answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Write data to CSV\n",
    "with open('ver2_baseline_model_questions_and_answers.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(csv_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
